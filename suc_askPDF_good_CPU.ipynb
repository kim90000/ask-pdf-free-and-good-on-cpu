{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94d2eb40b8734821ad0eb93efcb48f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02c220e5701b4042bd9ba3ebf9351daf",
              "IPY_MODEL_d3eb60ef9b234a1387cb71573d6b3ded",
              "IPY_MODEL_9204b844522149e0b6f83a0e2b98b703"
            ],
            "layout": "IPY_MODEL_c9029e89559947c29a1a70c5d5264e23"
          }
        },
        "02c220e5701b4042bd9ba3ebf9351daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84eec92ecf444543a49bcc488becaed3",
            "placeholder": "​",
            "style": "IPY_MODEL_bed35aaf5a754f74b279388626b49511",
            "value": "modules.json: 100%"
          }
        },
        "d3eb60ef9b234a1387cb71573d6b3ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a86c12a4b2840bd8f4049ce64192510",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37e0e9836e9e4e5881a42819eb0ebf46",
            "value": 349
          }
        },
        "9204b844522149e0b6f83a0e2b98b703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f5ce109ccd341b288d53eb2976e196a",
            "placeholder": "​",
            "style": "IPY_MODEL_827952a9f0604b73809426a473163892",
            "value": " 349/349 [00:00&lt;00:00, 26.9kB/s]"
          }
        },
        "c9029e89559947c29a1a70c5d5264e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84eec92ecf444543a49bcc488becaed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed35aaf5a754f74b279388626b49511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a86c12a4b2840bd8f4049ce64192510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e0e9836e9e4e5881a42819eb0ebf46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f5ce109ccd341b288d53eb2976e196a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827952a9f0604b73809426a473163892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ede50df27a3e46cf8ab799a9b93ee678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d9b3ff73cb649698f22d4cb61b5dfbf",
              "IPY_MODEL_49b2d2b6ec8e47f4b533cb0a5c49302d",
              "IPY_MODEL_cae2c02a66eb4cb7b2a6de3879e0fc5b"
            ],
            "layout": "IPY_MODEL_cc7def7872914ee79bac78925e5a18bb"
          }
        },
        "0d9b3ff73cb649698f22d4cb61b5dfbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1424bf550d0f4410b10659e3b1330d00",
            "placeholder": "​",
            "style": "IPY_MODEL_03659e28a6f5463b819303eaec2e473f",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "49b2d2b6ec8e47f4b533cb0a5c49302d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b69546c36fb64b15bc82c74a9649c6b8",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_294ed70500ba4980ba465234af05c7fc",
            "value": 116
          }
        },
        "cae2c02a66eb4cb7b2a6de3879e0fc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ed207d773142238475c6c99f640db1",
            "placeholder": "​",
            "style": "IPY_MODEL_7728d1d5e90f4bc49cbe370d0886722a",
            "value": " 116/116 [00:00&lt;00:00, 8.55kB/s]"
          }
        },
        "cc7def7872914ee79bac78925e5a18bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1424bf550d0f4410b10659e3b1330d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03659e28a6f5463b819303eaec2e473f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b69546c36fb64b15bc82c74a9649c6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294ed70500ba4980ba465234af05c7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40ed207d773142238475c6c99f640db1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7728d1d5e90f4bc49cbe370d0886722a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e982cc4f70943bb8802707e29224802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff23f68488b648bc891e31ecd377cf4e",
              "IPY_MODEL_7e9ac0295f594ed08ebcd6026481ebaa",
              "IPY_MODEL_79a6336dc5bb43b4b3bfb46469619714"
            ],
            "layout": "IPY_MODEL_2f77a9e7ee5e45d2b7ca0e1bd0ab87b9"
          }
        },
        "ff23f68488b648bc891e31ecd377cf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639ddf38b1004a0fa0921709922a1a2b",
            "placeholder": "​",
            "style": "IPY_MODEL_09133c3bc7ed4f299d73a47702fab6bd",
            "value": "README.md: 100%"
          }
        },
        "7e9ac0295f594ed08ebcd6026481ebaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33cac2fdf93746189ebb444592133c7d",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d75d49327e6c4770a1c6253563364956",
            "value": 10454
          }
        },
        "79a6336dc5bb43b4b3bfb46469619714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24d0b76f33646cab7d916111148d832",
            "placeholder": "​",
            "style": "IPY_MODEL_ff66c27da5114b29a6d5f7c4eda95bf9",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 776kB/s]"
          }
        },
        "2f77a9e7ee5e45d2b7ca0e1bd0ab87b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "639ddf38b1004a0fa0921709922a1a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09133c3bc7ed4f299d73a47702fab6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33cac2fdf93746189ebb444592133c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75d49327e6c4770a1c6253563364956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c24d0b76f33646cab7d916111148d832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff66c27da5114b29a6d5f7c4eda95bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1689550892db40c1a2832d4fef426a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afba3f51317f4dac846d4d57f633ec2b",
              "IPY_MODEL_47364daf83fb484fb52b3ba599158c10",
              "IPY_MODEL_1059e1a97af74916b09a487687dc61e4"
            ],
            "layout": "IPY_MODEL_185f65a45d56433f8b6b9c77eb491698"
          }
        },
        "afba3f51317f4dac846d4d57f633ec2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19107459242a4066ab3e8e895c517b7c",
            "placeholder": "​",
            "style": "IPY_MODEL_53f3974c7fa34cf4a2ee6d966b726160",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "47364daf83fb484fb52b3ba599158c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f619e9290842f7bb5fbfb9bd7e1ade",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_362272443ad04ed99b397682248e7ced",
            "value": 53
          }
        },
        "1059e1a97af74916b09a487687dc61e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2307c20a92a49039a9b53b19888832d",
            "placeholder": "​",
            "style": "IPY_MODEL_d45bf0c15fda4ba3b438092a4de6ac4c",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.54kB/s]"
          }
        },
        "185f65a45d56433f8b6b9c77eb491698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19107459242a4066ab3e8e895c517b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f3974c7fa34cf4a2ee6d966b726160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f619e9290842f7bb5fbfb9bd7e1ade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362272443ad04ed99b397682248e7ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2307c20a92a49039a9b53b19888832d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d45bf0c15fda4ba3b438092a4de6ac4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eddd04f4f7134e22993b72fd343e36fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b8894b06ac743fcb780739b0109e742",
              "IPY_MODEL_52a4c21946da4280b7ebedc299a6e546",
              "IPY_MODEL_1e6d74452cb94b558154e827acbbb833"
            ],
            "layout": "IPY_MODEL_8272ebf7c1a04f56bbeb8863eca86896"
          }
        },
        "3b8894b06ac743fcb780739b0109e742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0795a031c8412782cfc0450cabf344",
            "placeholder": "​",
            "style": "IPY_MODEL_70058b71679448fb841c4607357a7835",
            "value": "config.json: 100%"
          }
        },
        "52a4c21946da4280b7ebedc299a6e546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac11f82f11f41019adb36c4c7ea4859",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60c2c1f96dfc4b2184426478cbcf8c02",
            "value": 612
          }
        },
        "1e6d74452cb94b558154e827acbbb833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_189803e6660d4eacb8aa9dd2686e00ee",
            "placeholder": "​",
            "style": "IPY_MODEL_0f2ed942b96440868c8fc1162ceae00e",
            "value": " 612/612 [00:00&lt;00:00, 50.7kB/s]"
          }
        },
        "8272ebf7c1a04f56bbeb8863eca86896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0795a031c8412782cfc0450cabf344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70058b71679448fb841c4607357a7835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ac11f82f11f41019adb36c4c7ea4859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c2c1f96dfc4b2184426478cbcf8c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "189803e6660d4eacb8aa9dd2686e00ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2ed942b96440868c8fc1162ceae00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fa823f7b83c4aff93adc8d8a34555ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68c7a2e1174c479caaf0495c4bf4eb34",
              "IPY_MODEL_270d33edda7d4d87ac468eaac86fedbc",
              "IPY_MODEL_5a4eb1ec9edf44f98f8d0e598b5627d4"
            ],
            "layout": "IPY_MODEL_b3b0d8664aaa4e6d8bd8329a070eecc9"
          }
        },
        "68c7a2e1174c479caaf0495c4bf4eb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8672b0dc6b764abcbce4696ed0d1495f",
            "placeholder": "​",
            "style": "IPY_MODEL_427613a0880243d990624e4278daaf2d",
            "value": "model.safetensors: 100%"
          }
        },
        "270d33edda7d4d87ac468eaac86fedbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_706128da3b8f4b8ab4662f219fe39334",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be32ed79fa4b4f73b73bb0143b11c79f",
            "value": 90868376
          }
        },
        "5a4eb1ec9edf44f98f8d0e598b5627d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1361b0e747274e4d81b65d58d4931c31",
            "placeholder": "​",
            "style": "IPY_MODEL_8d3a9a85222346e3abc2f0ef62a825be",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 110MB/s]"
          }
        },
        "b3b0d8664aaa4e6d8bd8329a070eecc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8672b0dc6b764abcbce4696ed0d1495f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427613a0880243d990624e4278daaf2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "706128da3b8f4b8ab4662f219fe39334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be32ed79fa4b4f73b73bb0143b11c79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1361b0e747274e4d81b65d58d4931c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3a9a85222346e3abc2f0ef62a825be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e206109a65844501a7b2141a726621b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69097901839243d4aedc3c2ed83137de",
              "IPY_MODEL_c624b5040aac4dce9bae5c0e38656622",
              "IPY_MODEL_b32b39a95d674f64a3077078f69245d8"
            ],
            "layout": "IPY_MODEL_0475a2e5f34e4d28ac3c40f92f7ff754"
          }
        },
        "69097901839243d4aedc3c2ed83137de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3465678b8e54212b05b07bab1d7b331",
            "placeholder": "​",
            "style": "IPY_MODEL_37ed0d89a7274adbaf97152af22148f0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c624b5040aac4dce9bae5c0e38656622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c15c6a9709e45c7b51d7770e7dcc30c",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d211ce373c674d8f96c8f8707fe720bb",
            "value": 350
          }
        },
        "b32b39a95d674f64a3077078f69245d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8075d0ee26364e1bb562601f8e0c8432",
            "placeholder": "​",
            "style": "IPY_MODEL_0d41c340d2134b759a9a6046b6bbc2af",
            "value": " 350/350 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "0475a2e5f34e4d28ac3c40f92f7ff754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3465678b8e54212b05b07bab1d7b331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ed0d89a7274adbaf97152af22148f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c15c6a9709e45c7b51d7770e7dcc30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d211ce373c674d8f96c8f8707fe720bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8075d0ee26364e1bb562601f8e0c8432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d41c340d2134b759a9a6046b6bbc2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "324378bf132943c58f439744ca839a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26b9bd89369c43588f59add72d3bca29",
              "IPY_MODEL_9ebe5da8758549b4a46c60b8a02849b7",
              "IPY_MODEL_818c6f6504064c65b1b8b95e772d9d49"
            ],
            "layout": "IPY_MODEL_ef73d16b50ec40af98958d608a6ea1e3"
          }
        },
        "26b9bd89369c43588f59add72d3bca29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fa9999a0a6c41baa3e0d1b43daecba0",
            "placeholder": "​",
            "style": "IPY_MODEL_eb2f6b7d92d34bbfb9732de9a0e9284d",
            "value": "vocab.txt: 100%"
          }
        },
        "9ebe5da8758549b4a46c60b8a02849b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea35c1880d6b4ff8856269c1b542d5ea",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_408632aabb694b118961e9a5540780a7",
            "value": 231508
          }
        },
        "818c6f6504064c65b1b8b95e772d9d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c740b4bbf81946f19ac3efc708c79e76",
            "placeholder": "​",
            "style": "IPY_MODEL_f189de3209584082bacb694a1dd82a63",
            "value": " 232k/232k [00:00&lt;00:00, 569kB/s]"
          }
        },
        "ef73d16b50ec40af98958d608a6ea1e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa9999a0a6c41baa3e0d1b43daecba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2f6b7d92d34bbfb9732de9a0e9284d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea35c1880d6b4ff8856269c1b542d5ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408632aabb694b118961e9a5540780a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c740b4bbf81946f19ac3efc708c79e76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f189de3209584082bacb694a1dd82a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf110b5d7bc54daf9272687f1ca3029d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03d0947f9b5e4044b9d7b882823cf651",
              "IPY_MODEL_f2afff541b9b46b6a11f8b166f9d4af1",
              "IPY_MODEL_67c3b6d1940f41cd95f80f09daeb3df0"
            ],
            "layout": "IPY_MODEL_17119a50c3d54981a923c9e045213285"
          }
        },
        "03d0947f9b5e4044b9d7b882823cf651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc995731b5e94e32bf7c0917fcf9047c",
            "placeholder": "​",
            "style": "IPY_MODEL_333f35588df148988f84a5d3c7b0b8f5",
            "value": "tokenizer.json: 100%"
          }
        },
        "f2afff541b9b46b6a11f8b166f9d4af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3712e0983c5e4a51b9e93a61266360ba",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_494334d489de41b4acc5b85dfac3941e",
            "value": 466247
          }
        },
        "67c3b6d1940f41cd95f80f09daeb3df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb03d7fa41bb4866aac1a47f8e381c42",
            "placeholder": "​",
            "style": "IPY_MODEL_813292c20ec044698ee042b8868c68f7",
            "value": " 466k/466k [00:00&lt;00:00, 1.11MB/s]"
          }
        },
        "17119a50c3d54981a923c9e045213285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc995731b5e94e32bf7c0917fcf9047c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "333f35588df148988f84a5d3c7b0b8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3712e0983c5e4a51b9e93a61266360ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494334d489de41b4acc5b85dfac3941e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb03d7fa41bb4866aac1a47f8e381c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813292c20ec044698ee042b8868c68f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d09702b8dce54bdb8eb578810946405a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_027a3973e2a04353bdcff1e4c057f872",
              "IPY_MODEL_1828a01de4fe4af1aa08171651860708",
              "IPY_MODEL_96194c91bd0b4df8b8df1c4d6aeffbc2"
            ],
            "layout": "IPY_MODEL_50c15312668f40b48e059baa2a919516"
          }
        },
        "027a3973e2a04353bdcff1e4c057f872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0020ea817ad426d8895b1271a11f2c0",
            "placeholder": "​",
            "style": "IPY_MODEL_a8f6361e8cf142de85823af75b9d59d0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1828a01de4fe4af1aa08171651860708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac348a72893e4858932caaebe0723b51",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4595b6ae26f4b2bb5a5402b4c90cfa3",
            "value": 112
          }
        },
        "96194c91bd0b4df8b8df1c4d6aeffbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a817736b8544268614d46313cadd74",
            "placeholder": "​",
            "style": "IPY_MODEL_d6621d15d7054f268d8a27b9f4c9a38f",
            "value": " 112/112 [00:00&lt;00:00, 9.20kB/s]"
          }
        },
        "50c15312668f40b48e059baa2a919516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0020ea817ad426d8895b1271a11f2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f6361e8cf142de85823af75b9d59d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac348a72893e4858932caaebe0723b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4595b6ae26f4b2bb5a5402b4c90cfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8a817736b8544268614d46313cadd74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6621d15d7054f268d8a27b9f4c9a38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386eee9fd56842faae5d9a996d42c0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8b9cfde0ffe461c8430699a51b73a94",
              "IPY_MODEL_3c14abc6132144ed877c574c928df234",
              "IPY_MODEL_7e6dc986890149ac93b109177076cf1a"
            ],
            "layout": "IPY_MODEL_31ea9cc5ff904c198531df941d514b09"
          }
        },
        "c8b9cfde0ffe461c8430699a51b73a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21a04ed874847978ae1f81d001aee8e",
            "placeholder": "​",
            "style": "IPY_MODEL_ddffbb5233364728bc232c6b24e00f84",
            "value": "config.json: 100%"
          }
        },
        "3c14abc6132144ed877c574c928df234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c842eeb3efa48d2b0c9c1b780f2eda3",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e165ff536a9e43bbb182f6eae895cb03",
            "value": 190
          }
        },
        "7e6dc986890149ac93b109177076cf1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421c4d7b0f2943cdbf6912e0d3a8fa2c",
            "placeholder": "​",
            "style": "IPY_MODEL_89e76d0ea8ac4a47bc21812776ea0de1",
            "value": " 190/190 [00:00&lt;00:00, 17.3kB/s]"
          }
        },
        "31ea9cc5ff904c198531df941d514b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21a04ed874847978ae1f81d001aee8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddffbb5233364728bc232c6b24e00f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c842eeb3efa48d2b0c9c1b780f2eda3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e165ff536a9e43bbb182f6eae895cb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "421c4d7b0f2943cdbf6912e0d3a8fa2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89e76d0ea8ac4a47bc21812776ea0de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ycBbRaLWCw4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z21DC3W9Yjcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkAfNjhBYjut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSqh0qbCYjyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULkqRlvPYj1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8azYEj5dYj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnnuG8ZxYj9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTKp_V4YYkA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VaAx02AuYkEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "# from langchain_openai import ChatOpenAI # No longer using OpenAI\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain_openai import OpenAIEmbeddings # No longer using OpenAI embeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Define files path (corrected relative path)\n",
        "path = \"Understanding_Climate_Change.pdf\" # Assuming the PDF is in the same directory\n",
        "\n",
        "# Helper function to load and encode PDF\n",
        "def encode_pdf(pdf_path: str, chunk_size: int = 500, chunk_overlap: int = 50, embeddings_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"Loads a PDF, splits it into chunks, and encodes it into a FAISS vector store.\"\"\"\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        documents = loader.load()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at path: {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Use Hugging Face Embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
        "\n",
        "    # Create a FAISS vector store\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "#Initialize HuggingFaceHub language model\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
        "llm = HuggingFaceHub(repo_id=\"google/gemma-7b-it\", model_kwargs={\"max_length\": 1000, \"temperature\": 0.1})\n",
        "\n",
        "\n",
        "# Initialize search tool\n",
        "search = DuckDuckGoSearchResults()\n",
        "\n",
        "# Define retrieval evaluator, knowledge refinement, and query rewriter llm chains\n",
        "# Retrieval Evaluator\n",
        "class RetrievalEvaluatorInput(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n",
        "\n",
        "def retrieval_evaluator(query: str, document: str) -> float:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"document\"],\n",
        "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
        "    )\n",
        "    chain = prompt | llm | (lambda x: RetrievalEvaluatorInput(relevance_score=float(x))) #  Modified to work with HuggingFaceHub output\n",
        "    input_variables = {\"query\": query, \"document\": document}\n",
        "    try:\n",
        "        result = chain.invoke(input_variables).relevance_score\n",
        "        return float(result)\n",
        "    except:\n",
        "        return 0.5 # Return neutral value\n",
        "\n",
        "# Knowledge Refinement\n",
        "class KnowledgeRefinementInput(BaseModel):\n",
        "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
        "\n",
        "def knowledge_refinement(document: str) -> List[str]:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"document\"],\n",
        "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"document\": document}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
        "\n",
        "# Web Search Query Rewriter\n",
        "class QueryRewriterInput(BaseModel):\n",
        "    query: str = Field(..., description=\"The query to rewrite.\")\n",
        "\n",
        "def rewrite_query(query: str) -> str:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return result.strip()\n",
        "\n",
        "# Helper function to parse search results\n",
        "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Parse a JSON string of search results into a list of title-link tuples.\n",
        "\n",
        "    Args:\n",
        "        results_string (str): A JSON-formatted string containing search results.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
        "                               If parsing fails, an empty list is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to parse the JSON string\n",
        "        results = json.loads(results_string)\n",
        "        # Extract and return the title and link from each result\n",
        "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
        "    except (json.JSONDecodeError, TypeError):  # Handle TypeError as well\n",
        "        # Handle JSON decoding errors by returning an empty list\n",
        "        print(\"Error parsing search results. Returning empty list.\")\n",
        "        return []\n",
        "\n",
        "# Define sub functions for the CRAG process\n",
        "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Retrieve documents based on a query using a FAISS index.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
        "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of the retrieved document contents.\n",
        "    \"\"\"\n",
        "    docs = faiss_index.similarity_search(query, k=k)\n",
        "    return [doc.page_content for doc in docs]\n",
        "\n",
        "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Evaluate the relevance of documents based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        documents (List[str]): A list of document contents to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: A list of relevance scores for each document.\n",
        "    \"\"\"\n",
        "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
        "\n",
        "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
        "    \"\"\"\n",
        "    Perform a web search based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[Tuple[str, str]]]:\n",
        "            - A list of refined knowledge obtained from the web search.\n",
        "            - A list of tuples containing titles and links of the sources.\n",
        "    \"\"\"\n",
        "    rewritten_query = rewrite_query(query)\n",
        "    web_results = search.run(rewritten_query)\n",
        "    web_knowledge = knowledge_refinement(web_results)\n",
        "    sources = parse_search_results(web_results)\n",
        "    return web_knowledge, sources\n",
        "\n",
        "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response to a query using knowledge and sources.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        knowledge (str): The refined knowledge to use in the response.\n",
        "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    response_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
        "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
        "    )\n",
        "    input_variables = {\n",
        "        \"query\": query,\n",
        "        \"knowledge\": knowledge,\n",
        "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
        "    }\n",
        "    response_chain = response_prompt | llm\n",
        "    return response_chain.invoke(input_variables)\n",
        "\n",
        "# CRAG process\n",
        "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
        "    \"\"\"\n",
        "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to process.\n",
        "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response based on the query.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing query: {query}\")\n",
        "\n",
        "    # Retrieve and evaluate documents\n",
        "    if faiss_index is None:\n",
        "        return \"Error: FAISS index is not initialized. Please check if the PDF was loaded successfully.\"\n",
        "\n",
        "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
        "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
        "\n",
        "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
        "    print(f\"Evaluation scores: {eval_scores}\")\n",
        "\n",
        "    # Determine action based on evaluation scores\n",
        "    if eval_scores: # Ensure eval_scores is not empty\n",
        "        max_score = max(eval_scores)\n",
        "    else:\n",
        "        max_score = 0 # Default to 0 if no documents were retrieved.\n",
        "\n",
        "    sources = []\n",
        "\n",
        "    if max_score > 0.7:\n",
        "        print(\"\\nAction: Correct - Using retrieved document\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        final_knowledge = best_doc\n",
        "        sources.append((\"Retrieved document\", \"\"))\n",
        "    elif max_score < 0.3:\n",
        "        print(\"\\nAction: Incorrect - Performing web search\")\n",
        "        final_knowledge, sources = perform_web_search(query)\n",
        "    else:\n",
        "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        # Refine the retrieved knowledge\n",
        "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
        "        web_knowledge, web_sources = perform_web_search(query)\n",
        "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
        "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
        "\n",
        "    print(\"\\nFinal knowledge:\")\n",
        "    print(final_knowledge)\n",
        "\n",
        "    print(\"\\nSources:\")\n",
        "    for title, link in sources:\n",
        "        print(f\"{title}: {link}\" if link else title)\n",
        "\n",
        "    # Generate response\n",
        "    print(\"\\nGenerating response...\")\n",
        "    response = generate_response(query, final_knowledge, sources)\n",
        "\n",
        "    print(\"\\nResponse generated\")\n",
        "    return response\n",
        "\n",
        "# Initialize vector store\n",
        "vectorstore = encode_pdf(path)\n",
        "\n",
        "\n",
        "# Example queries\n",
        "query1 = \"What are the main causes of climate change?\"\n",
        "query2 = \"how did harry beat quirrell?\"\n",
        "\n",
        "# Process queries and print results\n",
        "if vectorstore:\n",
        "    result1 = crag_process(query1, vectorstore)\n",
        "    print(f\"Query: {query1}\")\n",
        "    print(f\"Answer: {result1}\")\n",
        "\n",
        "    result2 = crag_process(query2, vectorstore)\n",
        "    print(f\"Query: {query2}\")\n",
        "    print(f\"Answer: {result2}\")\n",
        "else:\n",
        "    print(\"Vectorstore was not initialized.  Please check the PDF loading process.\")"
      ],
      "metadata": {
        "id": "4iziy4prYkHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget import os\n",
        "import sys\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Define files path (corrected relative path)\n",
        "path = \"Understanding_Climate_Change.pdf\" # Assuming the PDF is in the same directory\n",
        "\n",
        "# Helper function to load and encode PDF\n",
        "def encode_pdf(pdf_path: str, chunk_size: int = 500, chunk_overlap: int = 50, embeddings_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"Loads a PDF, splits it into chunks, and encodes it into a FAISS vector store.\"\"\"\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        documents = loader.load()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at path: {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Use Hugging Face Embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
        "\n",
        "    # Create a FAISS vector store\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "#Initialize LlamaCpp language model\n",
        "model_path = \"path/to/your/llama3/model.gguf\"  # Replace with the actual path to your downloaded model\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=0, # Adjust based on your GPU, set to 0 if no GPU\n",
        "    n_batch=512,\n",
        "    n_ctx=2048, # adjust based on your model\n",
        "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=False, # Verbose is required to pass to the callback manager\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize search tool\n",
        "search = DuckDuckGoSearchResults()\n",
        "\n",
        "# Define retrieval evaluator, knowledge refinement, and query rewriter llm chains\n",
        "# Retrieval Evaluator\n",
        "class RetrievalEvaluatorInput(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n",
        "\n",
        "def retrieval_evaluator(query: str, document: str) -> float:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"document\"],\n",
        "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query, \"document\": document}\n",
        "    try:\n",
        "        result = chain.invoke(input_variables)\n",
        "        # Parse the output to extract the relevance score (assuming the model outputs a number)\n",
        "        try:\n",
        "            score = float(result.strip()) # Try to directly convert to float\n",
        "            return score\n",
        "        except ValueError:\n",
        "            # If direct conversion fails, try to extract the number from the text\n",
        "            import re\n",
        "            match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result) # Search for any float or integer\n",
        "            if match:\n",
        "                score = float(match.group(0))\n",
        "                return score\n",
        "            else:\n",
        "                return 0.5  # Return a neutral score if no number is found\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retrieval evaluator: {e}\")\n",
        "        return 0.5  # Return a neutral score in case of an exception\n",
        "\n",
        "\n",
        "\n",
        "# Knowledge Refinement\n",
        "class KnowledgeRefinementInput(BaseModel):\n",
        "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
        "\n",
        "def knowledge_refinement(document: str) -> List[str]:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"document\"],\n",
        "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"document\": document}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
        "\n",
        "# Web Search Query Rewriter\n",
        "class QueryRewriterInput(BaseModel):\n",
        "    query: str = Field(..., description=\"The query to rewrite.\")\n",
        "\n",
        "def rewrite_query(query: str) -> str:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return result.strip()\n",
        "\n",
        "# Helper function to parse search results\n",
        "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Parse a JSON string of search results into a list of title-link tuples.\n",
        "\n",
        "    Args:\n",
        "        results_string (str): A JSON-formatted string containing search results.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
        "                               If parsing fails, an empty list is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to parse the JSON string\n",
        "        results = json.loads(results_string)\n",
        "        # Extract and return the title and link from each result\n",
        "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
        "    except (json.JSONDecodeError, TypeError):  # Handle TypeError as well\n",
        "        # Handle JSON decoding errors by returning an empty list\n",
        "        print(\"Error parsing search results. Returning empty list.\")\n",
        "        return []\n",
        "\n",
        "# Define sub functions for the CRAG process\n",
        "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Retrieve documents based on a query using a FAISS index.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
        "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of the retrieved document contents.\n",
        "    \"\"\"\n",
        "    docs = faiss_index.similarity_search(query, k=k)\n",
        "    return [doc.page_content for doc in docs]\n",
        "\n",
        "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Evaluate the relevance of documents based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        documents (List[str]): A list of document contents to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: A list of relevance scores for each document.\n",
        "    \"\"\"\n",
        "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
        "\n",
        "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
        "    \"\"\"\n",
        "    Perform a web search based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[Tuple[str, str]]]:\n",
        "            - A list of refined knowledge obtained from the web search.\n",
        "            - A list of tuples containing titles and links of the sources.\n",
        "    \"\"\"\n",
        "    rewritten_query = rewrite_query(query)\n",
        "    web_results = search.run(rewritten_query)\n",
        "    web_knowledge = knowledge_refinement(web_results)\n",
        "    sources = parse_search_results(web_results)\n",
        "    return web_knowledge, sources\n",
        "\n",
        "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response to a query using knowledge and sources.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        knowledge (str): The refined knowledge to use in the response.\n",
        "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    response_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
        "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
        "    )\n",
        "    input_variables = {\n",
        "        \"query\": query,\n",
        "        \"knowledge\": knowledge,\n",
        "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
        "    }\n",
        "    response_chain = response_prompt | llm\n",
        "    return response_chain.invoke(input_variables)\n",
        "\n",
        "# CRAG process\n",
        "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
        "    \"\"\"\n",
        "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to process.\n",
        "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response based on the query.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing query: {query}\")\n",
        "\n",
        "    # Retrieve and evaluate documents\n",
        "    if faiss_index is None:\n",
        "        return \"Error: FAISS index is not initialized. Please check if the PDF was loaded successfully.\"\n",
        "\n",
        "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
        "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
        "\n",
        "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
        "    print(f\"Evaluation scores: {eval_scores}\")\n",
        "\n",
        "    # Determine action based on evaluation scores\n",
        "    if eval_scores: # Ensure eval_scores is not empty\n",
        "        max_score = max(eval_scores)\n",
        "    else:\n",
        "        max_score = 0 # Default to 0 if no documents were retrieved.\n",
        "\n",
        "    sources = []\n",
        "\n",
        "    if max_score > 0.7:\n",
        "        print(\"\\nAction: Correct - Using retrieved document\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        final_knowledge = best_doc\n",
        "        sources.append((\"Retrieved document\", \"\"))\n",
        "    elif max_score < 0.3:\n",
        "        print(\"\\nAction: Incorrect - Performing web search\")\n",
        "        final_knowledge, sources = perform_web_search(query)\n",
        "    else:\n",
        "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        # Refine the retrieved knowledge\n",
        "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
        "        web_knowledge, web_sources = perform_web_search(query)\n",
        "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
        "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
        "\n",
        "    print(\"\\nFinal knowledge:\")\n",
        "    print(final_knowledge)\n",
        "\n",
        "    print(\"\\nSources:\")\n",
        "    for title, link in sources:\n",
        "        print(f\"{title}: {link}\" if link else title)\n",
        "\n",
        "    # Generate response\n",
        "    print(\"\\nGenerating response...\")\n",
        "    response = generate_response(query, final_knowledge, sources)\n",
        "\n",
        "    print(\"\\nResponse generated\")\n",
        "    return response\n",
        "\n",
        "# Initialize vector store\n",
        "vectorstore = encode_pdf(path)\n",
        "\n",
        "\n",
        "# Example queries\n",
        "query1 = \"What are the main causes of climate change?\"\n",
        "query2 = \"how did harry beat quirrell?\"\n",
        "\n",
        "# Process queries and print results\n",
        "if vectorstore:\n",
        "    result1 = crag_process(query1, vectorstore)\n",
        "    print(f\"Query: {query1}\")\n",
        "    print(f\"Answer: {result1}\")\n",
        "\n",
        "    result2 = crag_process(query2, vectorstore)\n",
        "    print(f\"Query: {query2}\")\n",
        "    print(f\"Answer: {result2}\")\n",
        "else:\n",
        "    print(\"Vectorstore was not initialized.  Please check the PDF loading process.\")"
      ],
      "metadata": {
        "id": "sx-7hx81ZruW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/bartowski/Dolphin3.0-Llama3.2-3B-GGUF/resolve/main/Dolphin3.0-Llama3.2-3B-IQ2_M.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQiIvN3YZvrA",
        "outputId": "07b0a935-3bae-459d-bac9-4d1a9a969ea3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-30 00:15:33--  https://huggingface.co/bartowski/Dolphin3.0-Llama3.2-3B-GGUF/resolve/main/Dolphin3.0-Llama3.2-3B-IQ2_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 54.230.71.28, 54.230.71.2, 54.230.71.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|54.230.71.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/ea/41/ea41d1c9c4625bf2ce1b727f47334106ae8b50891147f1cf6d91a6c6a4c284a7/dc07e2f0dfd4a0882aa5b3f1e6fba1fde504e14209623e3b38d296384bcd29e5?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Dolphin3.0-Llama3.2-3B-IQ2_M.gguf%3B+filename%3D%22Dolphin3.0-Llama3.2-3B-IQ2_M.gguf%22%3B&Expires=1743297333&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzI5NzMzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2VhLzQxL2VhNDFkMWM5YzQ2MjViZjJjZTFiNzI3ZjQ3MzM0MTA2YWU4YjUwODkxMTQ3ZjFjZjZkOTFhNmM2YTRjMjg0YTcvZGMwN2UyZjBkZmQ0YTA4ODJhYTViM2YxZTZmYmExZmRlNTA0ZTE0MjA5NjIzZTNiMzhkMjk2Mzg0YmNkMjllNT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=UEGlZRASEB%7ELM2G5vqnhNcdtOETDkeWk1MHA7wZZDn5nqhPHHK1kf0fkqupegAaUxJTUB1mDQK7OGSrCxD4b0oMiiygQIe2LYBEULUDocsMf6KvqKloxwvovRol2V3ftFBjQHwRPGRHBT7kAxrRtS7kzqWSjWt2Mk4rWLLZVFKq%7EexESaDXOVp53TVR2EJulZImZrkZWlaZpsfgKZt4Ni3yVo2%7EXV25ON1iraN02hVL394xz-50qUycM1hJX8hZCZSZo3k1DExBb5Vg3f2y1FhFO03b88yqY58CEhNPm66D6ZwJQJ1HrEeBAfJq%7EiF-ncaTshpHN1uvh4oLmeM%7EPTg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-03-30 00:15:33--  https://cdn-lfs-us-1.hf.co/repos/ea/41/ea41d1c9c4625bf2ce1b727f47334106ae8b50891147f1cf6d91a6c6a4c284a7/dc07e2f0dfd4a0882aa5b3f1e6fba1fde504e14209623e3b38d296384bcd29e5?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Dolphin3.0-Llama3.2-3B-IQ2_M.gguf%3B+filename%3D%22Dolphin3.0-Llama3.2-3B-IQ2_M.gguf%22%3B&Expires=1743297333&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzI5NzMzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2VhLzQxL2VhNDFkMWM5YzQ2MjViZjJjZTFiNzI3ZjQ3MzM0MTA2YWU4YjUwODkxMTQ3ZjFjZjZkOTFhNmM2YTRjMjg0YTcvZGMwN2UyZjBkZmQ0YTA4ODJhYTViM2YxZTZmYmExZmRlNTA0ZTE0MjA5NjIzZTNiMzhkMjk2Mzg0YmNkMjllNT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=UEGlZRASEB%7ELM2G5vqnhNcdtOETDkeWk1MHA7wZZDn5nqhPHHK1kf0fkqupegAaUxJTUB1mDQK7OGSrCxD4b0oMiiygQIe2LYBEULUDocsMf6KvqKloxwvovRol2V3ftFBjQHwRPGRHBT7kAxrRtS7kzqWSjWt2Mk4rWLLZVFKq%7EexESaDXOVp53TVR2EJulZImZrkZWlaZpsfgKZt4Ni3yVo2%7EXV25ON1iraN02hVL394xz-50qUycM1hJX8hZCZSZo3k1DExBb5Vg3f2y1FhFO03b88yqY58CEhNPm66D6ZwJQJ1HrEeBAfJq%7EiF-ncaTshpHN1uvh4oLmeM%7EPTg__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.35.186.84, 13.35.186.39, 13.35.186.54, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.35.186.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1229035840 (1.1G) [binary/octet-stream]\n",
            "Saving to: ‘Dolphin3.0-Llama3.2-3B-IQ2_M.gguf’\n",
            "\n",
            "Dolphin3.0-Llama3.2 100%[===================>]   1.14G  23.1MB/s    in 51s     \n",
            "\n",
            "2025-03-30 00:16:24 (23.1 MB/s) - ‘Dolphin3.0-Llama3.2-3B-IQ2_M.gguf’ saved [1229035840/1229035840]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install faiss-cpu  # Or faiss-gpu if you have a GPU\n",
        "!pip install python-dotenv\n",
        "!pip install pypdf\n",
        "!pip install duckduckgo-search\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install sentence_transformersimport os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFvFF-1raDSe",
        "outputId": "b840e06b-8149-4273-ec32-9ccf5f530c89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.47)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.4.0\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-7.5.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Collecting primp>=0.14.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.1)\n",
            "Downloading duckduckgo_search-7.5.5-py3-none-any.whl (20 kB)\n",
            "Downloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-7.5.5 primp-0.14.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.29.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sentence_transformersimport (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sentence_transformersimport\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bjk1qVIafWY",
        "outputId": "346355cc-fdc7-4d53-f421-11b93b841c4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp311-cp311-linux_x86_64.whl size=5959615 sha256=7d0e99d019bc18f242d6f9034a0683e0c10cfc661d456e80a8bb7d0296afd262\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/03/66/eb3810eafd55d921b2be32896d1f44313996982360663aa80b\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/NirDiamant/RAG_Techniques"
      ],
      "metadata": {
        "id": "uiD75ZiebTL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb"
      ],
      "metadata": {
        "id": "KrKKDGfsbWPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TzC5_Uzb0YO",
        "outputId": "ad7b5c0a-5ee6-493e-ab0b-bd8e76f5c459"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.47)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.18)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال جيد"
      ],
      "metadata": {
        "id": "vwI12WELeAFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Define files path (corrected relative path)\n",
        "path = \"Understanding_Climate_Change.pdf\" # Assuming the PDF is in the same directory\n",
        "\n",
        "# Helper function to load and encode PDF\n",
        "def encode_pdf(pdf_path: str, chunk_size: int = 500, chunk_overlap: int = 50, embeddings_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"Loads a PDF, splits it into chunks, and encodes it into a FAISS vector store.\"\"\"\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        documents = loader.load()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at path: {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Use Hugging Face Embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
        "\n",
        "    # Create a FAISS vector store\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "#Initialize LlamaCpp language model\n",
        "model_path = \"/content/Dolphin3.0-Llama3.2-3B-IQ2_M.gguf\"  # Replace with the actual path to your downloaded model\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=0, # Adjust based on your GPU, set to 0 if no GPU\n",
        "    n_batch=512,\n",
        "    n_ctx=2048, # adjust based on your model\n",
        "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=False, # Verbose is required to pass to the callback manager\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize search tool\n",
        "search = DuckDuckGoSearchResults()\n",
        "\n",
        "# Define retrieval evaluator, knowledge refinement, and query rewriter llm chains\n",
        "# Retrieval Evaluator\n",
        "class RetrievalEvaluatorInput(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n",
        "\n",
        "def retrieval_evaluator(query: str, document: str) -> float:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"document\"],\n",
        "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query, \"document\": document}\n",
        "    try:\n",
        "        result = chain.invoke(input_variables)\n",
        "        # Parse the output to extract the relevance score (assuming the model outputs a number)\n",
        "        try:\n",
        "            score = float(result.strip()) # Try to directly convert to float\n",
        "            return score\n",
        "        except ValueError:\n",
        "            # If direct conversion fails, try to extract the number from the text\n",
        "            import re\n",
        "            match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result) # Search for any float or integer\n",
        "            if match:\n",
        "                score = float(match.group(0))\n",
        "                return score\n",
        "            else:\n",
        "                return 0.5  # Return a neutral score if no number is found\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retrieval evaluator: {e}\")\n",
        "        return 0.5  # Return a neutral score in case of an exception\n",
        "\n",
        "\n",
        "\n",
        "# Knowledge Refinement\n",
        "class KnowledgeRefinementInput(BaseModel):\n",
        "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
        "\n",
        "def knowledge_refinement(document: str) -> List[str]:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"document\"],\n",
        "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"document\": document}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
        "\n",
        "# Web Search Query Rewriter\n",
        "class QueryRewriterInput(BaseModel):\n",
        "    query: str = Field(..., description=\"The query to rewrite.\")\n",
        "\n",
        "def rewrite_query(query: str) -> str:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return result.strip()\n",
        "\n",
        "# Helper function to parse search results\n",
        "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Parse a JSON string of search results into a list of title-link tuples.\n",
        "\n",
        "    Args:\n",
        "        results_string (str): A JSON-formatted string containing search results.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
        "                               If parsing fails, an empty list is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to parse the JSON string\n",
        "        results = json.loads(results_string)\n",
        "        # Extract and return the title and link from each result\n",
        "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
        "    except (json.JSONDecodeError, TypeError):  # Handle TypeError as well\n",
        "        # Handle JSON decoding errors by returning an empty list\n",
        "        print(\"Error parsing search results. Returning empty list.\")\n",
        "        return []\n",
        "\n",
        "# Define sub functions for the CRAG process\n",
        "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Retrieve documents based on a query using a FAISS index.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
        "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of the retrieved document contents.\n",
        "    \"\"\"\n",
        "    docs = faiss_index.similarity_search(query, k=k)\n",
        "    return [doc.page_content for doc in docs]\n",
        "\n",
        "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Evaluate the relevance of documents based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        documents (List[str]): A list of document contents to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: A list of relevance scores for each document.\n",
        "    \"\"\"\n",
        "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
        "\n",
        "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
        "    \"\"\"\n",
        "    Perform a web search based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[Tuple[str, str]]]:\n",
        "            - A list of refined knowledge obtained from the web search.\n",
        "            - A list of tuples containing titles and links of the sources.\n",
        "    \"\"\"\n",
        "    rewritten_query = rewrite_query(query)\n",
        "    web_results = search.run(rewritten_query)\n",
        "    web_knowledge = knowledge_refinement(web_results)\n",
        "    sources = parse_search_results(web_results)\n",
        "    return web_knowledge, sources\n",
        "\n",
        "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response to a query using knowledge and sources.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        knowledge (str): The refined knowledge to use in the response.\n",
        "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    response_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
        "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
        "    )\n",
        "    input_variables = {\n",
        "        \"query\": query,\n",
        "        \"knowledge\": knowledge,\n",
        "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
        "    }\n",
        "    response_chain = response_prompt | llm\n",
        "    return response_chain.invoke(input_variables)\n",
        "\n",
        "# CRAG process\n",
        "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
        "    \"\"\"\n",
        "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to process.\n",
        "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response based on the query.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing query: {query}\")\n",
        "\n",
        "    # Retrieve and evaluate documents\n",
        "    if faiss_index is None:\n",
        "        return \"Error: FAISS index is not initialized. Please check if the PDF was loaded successfully.\"\n",
        "\n",
        "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
        "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
        "\n",
        "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
        "    print(f\"Evaluation scores: {eval_scores}\")\n",
        "\n",
        "    # Determine action based on evaluation scores\n",
        "    if eval_scores: # Ensure eval_scores is not empty\n",
        "        max_score = max(eval_scores)\n",
        "    else:\n",
        "        max_score = 0 # Default to 0 if no documents were retrieved.\n",
        "\n",
        "    sources = []\n",
        "\n",
        "    if max_score > 0.7:\n",
        "        print(\"\\nAction: Correct - Using retrieved document\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        final_knowledge = best_doc\n",
        "        sources.append((\"Retrieved document\", \"\"))\n",
        "    elif max_score < 0.3:\n",
        "        print(\"\\nAction: Incorrect - Performing web search\")\n",
        "        final_knowledge, sources = perform_web_search(query)\n",
        "    else:\n",
        "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        # Refine the retrieved knowledge\n",
        "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
        "        web_knowledge, web_sources = perform_web_search(query)\n",
        "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
        "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
        "\n",
        "    print(\"\\nFinal knowledge:\")\n",
        "    print(final_knowledge)\n",
        "\n",
        "    print(\"\\nSources:\")\n",
        "    for title, link in sources:\n",
        "        print(f\"{title}: {link}\" if link else title)\n",
        "\n",
        "    # Generate response\n",
        "    print(\"\\nGenerating response...\")\n",
        "    response = generate_response(query, final_knowledge, sources)\n",
        "\n",
        "    print(\"\\nResponse generated\")\n",
        "    return response\n",
        "\n",
        "# Initialize vector store\n",
        "vectorstore = encode_pdf(path)\n",
        "\n",
        "\n",
        "# Example queries\n",
        "query1 = \"What are the main causes of climate change?\"\n",
        "query2 = \"how did harry beat quirrell?\"\n",
        "\n",
        "# Process queries and print results\n",
        "if vectorstore:\n",
        "    result1 = crag_process(query1, vectorstore)\n",
        "    print(f\"Query: {query1}\")\n",
        "    print(f\"Answer: {result1}\")\n",
        "\n",
        "    result2 = crag_process(query2, vectorstore)\n",
        "    print(f\"Query: {query2}\")\n",
        "    print(f\"Answer: {result2}\")\n",
        "else:\n",
        "    print(\"Vectorstore was not initialized.  Please check the PDF loading process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "94d2eb40b8734821ad0eb93efcb48f98",
            "02c220e5701b4042bd9ba3ebf9351daf",
            "d3eb60ef9b234a1387cb71573d6b3ded",
            "9204b844522149e0b6f83a0e2b98b703",
            "c9029e89559947c29a1a70c5d5264e23",
            "84eec92ecf444543a49bcc488becaed3",
            "bed35aaf5a754f74b279388626b49511",
            "3a86c12a4b2840bd8f4049ce64192510",
            "37e0e9836e9e4e5881a42819eb0ebf46",
            "5f5ce109ccd341b288d53eb2976e196a",
            "827952a9f0604b73809426a473163892",
            "ede50df27a3e46cf8ab799a9b93ee678",
            "0d9b3ff73cb649698f22d4cb61b5dfbf",
            "49b2d2b6ec8e47f4b533cb0a5c49302d",
            "cae2c02a66eb4cb7b2a6de3879e0fc5b",
            "cc7def7872914ee79bac78925e5a18bb",
            "1424bf550d0f4410b10659e3b1330d00",
            "03659e28a6f5463b819303eaec2e473f",
            "b69546c36fb64b15bc82c74a9649c6b8",
            "294ed70500ba4980ba465234af05c7fc",
            "40ed207d773142238475c6c99f640db1",
            "7728d1d5e90f4bc49cbe370d0886722a",
            "9e982cc4f70943bb8802707e29224802",
            "ff23f68488b648bc891e31ecd377cf4e",
            "7e9ac0295f594ed08ebcd6026481ebaa",
            "79a6336dc5bb43b4b3bfb46469619714",
            "2f77a9e7ee5e45d2b7ca0e1bd0ab87b9",
            "639ddf38b1004a0fa0921709922a1a2b",
            "09133c3bc7ed4f299d73a47702fab6bd",
            "33cac2fdf93746189ebb444592133c7d",
            "d75d49327e6c4770a1c6253563364956",
            "c24d0b76f33646cab7d916111148d832",
            "ff66c27da5114b29a6d5f7c4eda95bf9",
            "1689550892db40c1a2832d4fef426a7c",
            "afba3f51317f4dac846d4d57f633ec2b",
            "47364daf83fb484fb52b3ba599158c10",
            "1059e1a97af74916b09a487687dc61e4",
            "185f65a45d56433f8b6b9c77eb491698",
            "19107459242a4066ab3e8e895c517b7c",
            "53f3974c7fa34cf4a2ee6d966b726160",
            "99f619e9290842f7bb5fbfb9bd7e1ade",
            "362272443ad04ed99b397682248e7ced",
            "f2307c20a92a49039a9b53b19888832d",
            "d45bf0c15fda4ba3b438092a4de6ac4c",
            "eddd04f4f7134e22993b72fd343e36fd",
            "3b8894b06ac743fcb780739b0109e742",
            "52a4c21946da4280b7ebedc299a6e546",
            "1e6d74452cb94b558154e827acbbb833",
            "8272ebf7c1a04f56bbeb8863eca86896",
            "fe0795a031c8412782cfc0450cabf344",
            "70058b71679448fb841c4607357a7835",
            "3ac11f82f11f41019adb36c4c7ea4859",
            "60c2c1f96dfc4b2184426478cbcf8c02",
            "189803e6660d4eacb8aa9dd2686e00ee",
            "0f2ed942b96440868c8fc1162ceae00e",
            "3fa823f7b83c4aff93adc8d8a34555ce",
            "68c7a2e1174c479caaf0495c4bf4eb34",
            "270d33edda7d4d87ac468eaac86fedbc",
            "5a4eb1ec9edf44f98f8d0e598b5627d4",
            "b3b0d8664aaa4e6d8bd8329a070eecc9",
            "8672b0dc6b764abcbce4696ed0d1495f",
            "427613a0880243d990624e4278daaf2d",
            "706128da3b8f4b8ab4662f219fe39334",
            "be32ed79fa4b4f73b73bb0143b11c79f",
            "1361b0e747274e4d81b65d58d4931c31",
            "8d3a9a85222346e3abc2f0ef62a825be",
            "e206109a65844501a7b2141a726621b9",
            "69097901839243d4aedc3c2ed83137de",
            "c624b5040aac4dce9bae5c0e38656622",
            "b32b39a95d674f64a3077078f69245d8",
            "0475a2e5f34e4d28ac3c40f92f7ff754",
            "a3465678b8e54212b05b07bab1d7b331",
            "37ed0d89a7274adbaf97152af22148f0",
            "2c15c6a9709e45c7b51d7770e7dcc30c",
            "d211ce373c674d8f96c8f8707fe720bb",
            "8075d0ee26364e1bb562601f8e0c8432",
            "0d41c340d2134b759a9a6046b6bbc2af",
            "324378bf132943c58f439744ca839a60",
            "26b9bd89369c43588f59add72d3bca29",
            "9ebe5da8758549b4a46c60b8a02849b7",
            "818c6f6504064c65b1b8b95e772d9d49",
            "ef73d16b50ec40af98958d608a6ea1e3",
            "6fa9999a0a6c41baa3e0d1b43daecba0",
            "eb2f6b7d92d34bbfb9732de9a0e9284d",
            "ea35c1880d6b4ff8856269c1b542d5ea",
            "408632aabb694b118961e9a5540780a7",
            "c740b4bbf81946f19ac3efc708c79e76",
            "f189de3209584082bacb694a1dd82a63",
            "cf110b5d7bc54daf9272687f1ca3029d",
            "03d0947f9b5e4044b9d7b882823cf651",
            "f2afff541b9b46b6a11f8b166f9d4af1",
            "67c3b6d1940f41cd95f80f09daeb3df0",
            "17119a50c3d54981a923c9e045213285",
            "fc995731b5e94e32bf7c0917fcf9047c",
            "333f35588df148988f84a5d3c7b0b8f5",
            "3712e0983c5e4a51b9e93a61266360ba",
            "494334d489de41b4acc5b85dfac3941e",
            "cb03d7fa41bb4866aac1a47f8e381c42",
            "813292c20ec044698ee042b8868c68f7",
            "d09702b8dce54bdb8eb578810946405a",
            "027a3973e2a04353bdcff1e4c057f872",
            "1828a01de4fe4af1aa08171651860708",
            "96194c91bd0b4df8b8df1c4d6aeffbc2",
            "50c15312668f40b48e059baa2a919516",
            "d0020ea817ad426d8895b1271a11f2c0",
            "a8f6361e8cf142de85823af75b9d59d0",
            "ac348a72893e4858932caaebe0723b51",
            "b4595b6ae26f4b2bb5a5402b4c90cfa3",
            "b8a817736b8544268614d46313cadd74",
            "d6621d15d7054f268d8a27b9f4c9a38f",
            "386eee9fd56842faae5d9a996d42c0c2",
            "c8b9cfde0ffe461c8430699a51b73a94",
            "3c14abc6132144ed877c574c928df234",
            "7e6dc986890149ac93b109177076cf1a",
            "31ea9cc5ff904c198531df941d514b09",
            "e21a04ed874847978ae1f81d001aee8e",
            "ddffbb5233364728bc232c6b24e00f84",
            "2c842eeb3efa48d2b0c9c1b780f2eda3",
            "e165ff536a9e43bbb182f6eae895cb03",
            "421c4d7b0f2943cdbf6912e0d3a8fa2c",
            "89e76d0ea8ac4a47bc21812776ea0de1"
          ]
        },
        "id": "_-Z2DKlAZOd1",
        "outputId": "d969efb7-4526-4e45-8dc8-7038c2c7dff5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "<ipython-input-6-e310ae111767>:40: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94d2eb40b8734821ad0eb93efcb48f98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ede50df27a3e46cf8ab799a9b93ee678"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e982cc4f70943bb8802707e29224802"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1689550892db40c1a2832d4fef426a7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eddd04f4f7134e22993b72fd343e36fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fa823f7b83c4aff93adc8d8a34555ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e206109a65844501a7b2141a726621b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "324378bf132943c58f439744ca839a60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf110b5d7bc54daf9272687f1ca3029d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d09702b8dce54bdb8eb578810946405a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "386eee9fd56842faae5d9a996d42c0c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing query: What are the main causes of climate change?\n",
            " 1 - 0 = 1\n",
            "\n",
            "The score reflects the extent to which this document addresses the query and provides information about how recent changes are primarily driven by human activities, particularly the emission of greenhouse gases. 0.9\n",
            "Relevance to the query: High \n",
            "- The main causes of climate change include, but not exclusively, human activities such as burning fossil fuels and deforestating plants for use in energy production. 0 (N/A) because there is no information about the document relevance to the query. \n",
            "Relevance score: 1 (Highly relevant, as it provides a comprehensive understanding of the causes and effects of climate change.)\n",
            "The following document is relevant to the query regarding what are the main causes of climate change.\n",
            "However, according to the provided document, Food and Water Security relates more closely to the cause and effect of climate change compared to respiratory and cardiovascular diseases.\n",
            "\n",
            "Relevance score: 0.5 (Somewhat relevant)\n",
            "Retrieved 3 documents\n",
            "Evaluation scores: [1.0, 0.9, 0.0]\n",
            "\n",
            "Action: Correct - Using retrieved document\n",
            "\n",
            "Final knowledge:\n",
            "provide a historical record that scientists use to understand past climate conditions and \n",
            "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
            "driven by human activities, particularly the emission of greenhouse gases. \n",
            "Chapter 2: Causes of Climate Change \n",
            "Greenhouse Gases \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous\n",
            "\n",
            "Sources:\n",
            "Retrieved document\n",
            "\n",
            "Generating response...\n",
            " Based on the following knowledge, recent changes in the climate are primarily driven by human activities. These activities have been characterized as being responsible for a significant increase in greenhouse gases"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e310ae111767>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;31m# Process queries and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrag_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Query: {query1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Answer: {result1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e310ae111767>\u001b[0m in \u001b[0;36mcrag_process\u001b[0;34m(query, faiss_index)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# Generate response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGenerating response...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_knowledge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nResponse generated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e310ae111767>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(query, knowledge, sources)\u001b[0m\n\u001b[1;32m    215\u001b[0m     }\n\u001b[1;32m    216\u001b[0m     \u001b[0mresponse_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_prompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;31m# CRAG process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3023\u001b[0m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3025\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3026\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         return (\n\u001b[0;32m--> 390\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    762\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 )\n\u001b[1;32m    965\u001b[0m             ]\n\u001b[0;32m--> 966\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    967\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             output = (\n\u001b[0;32m--> 787\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    788\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m             text = (\n\u001b[0;32m-> 1526\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/llms/llamacpp.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m# and return the combined strings from the first choices's text:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcombined_text_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             for chunk in self._stream(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/llms/llamacpp.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             chunk = GenerationChunk(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m_create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0mfinish_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"length\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mmultibyte_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         for token in self.generate(\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;31m# Eval and sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 token = self.sample(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             )\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;31m# Save tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_past\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mn_past\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/_internals.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLlamaBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         return_code = llama_cpp.llama_decode(\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/bartowski/Dolphin3.0-Llama3.2-3B-GGUF/resolve/main/Dolphin3.0-Llama3.2-3B-Q8_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHKiCJ_yc66f",
        "outputId": "4a76f3d1-aeb8-4ceb-b92c-9ae919ba9713"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-30 00:33:09--  https://huggingface.co/bartowski/Dolphin3.0-Llama3.2-3B-GGUF/resolve/main/Dolphin3.0-Llama3.2-3B-Q8_0.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 54.230.71.56, 54.230.71.103, 54.230.71.2, ...\n",
            "Connecting to huggingface.co (huggingface.co)|54.230.71.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/ea/41/ea41d1c9c4625bf2ce1b727f47334106ae8b50891147f1cf6d91a6c6a4c284a7/d7a51f65ebd35e7e7da5632274183c9b54f38330e015a6c73adca0bf3523fdae?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Dolphin3.0-Llama3.2-3B-Q8_0.gguf%3B+filename%3D%22Dolphin3.0-Llama3.2-3B-Q8_0.gguf%22%3B&Expires=1743298389&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzI5ODM4OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2VhLzQxL2VhNDFkMWM5YzQ2MjViZjJjZTFiNzI3ZjQ3MzM0MTA2YWU4YjUwODkxMTQ3ZjFjZjZkOTFhNmM2YTRjMjg0YTcvZDdhNTFmNjVlYmQzNWU3ZTdkYTU2MzIyNzQxODNjOWI1NGYzODMzMGUwMTVhNmM3M2FkY2EwYmYzNTIzZmRhZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=smKj9oKN8%7EmOKG1WIMABT43c5eokcM74AyR8Pb6ObP%7E9JDSwOylyPS3ilQVVDl9OrrsETq8jctP4jGGkPf8T%7E4O0QxABhjmOr2UhA0Q2M5LwJS%7Ed2el9qgSWhRTqtxQu9fNzwnJqxVIofiqnZjYpaBnSDD1bs2QJvAXetlcHP3ynzCkX6y7TRdqpmnw8GGGKN%7EgU57mthuczk1L8-Z93pMatp18jko%7EZxJCjoNyLUugaif%7Epd5eDb2dRNvkD0a3ysFohoAfVFZnJAf9ZZi7oWgDaoOMUvfWV5eB48fMhnu3aENnmMCgUeiVHEV7IycasWp5LC9B6Z%7E-1z5-kDKwIRg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-03-30 00:33:09--  https://cdn-lfs-us-1.hf.co/repos/ea/41/ea41d1c9c4625bf2ce1b727f47334106ae8b50891147f1cf6d91a6c6a4c284a7/d7a51f65ebd35e7e7da5632274183c9b54f38330e015a6c73adca0bf3523fdae?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Dolphin3.0-Llama3.2-3B-Q8_0.gguf%3B+filename%3D%22Dolphin3.0-Llama3.2-3B-Q8_0.gguf%22%3B&Expires=1743298389&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzI5ODM4OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2VhLzQxL2VhNDFkMWM5YzQ2MjViZjJjZTFiNzI3ZjQ3MzM0MTA2YWU4YjUwODkxMTQ3ZjFjZjZkOTFhNmM2YTRjMjg0YTcvZDdhNTFmNjVlYmQzNWU3ZTdkYTU2MzIyNzQxODNjOWI1NGYzODMzMGUwMTVhNmM3M2FkY2EwYmYzNTIzZmRhZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=smKj9oKN8%7EmOKG1WIMABT43c5eokcM74AyR8Pb6ObP%7E9JDSwOylyPS3ilQVVDl9OrrsETq8jctP4jGGkPf8T%7E4O0QxABhjmOr2UhA0Q2M5LwJS%7Ed2el9qgSWhRTqtxQu9fNzwnJqxVIofiqnZjYpaBnSDD1bs2QJvAXetlcHP3ynzCkX6y7TRdqpmnw8GGGKN%7EgU57mthuczk1L8-Z93pMatp18jko%7EZxJCjoNyLUugaif%7Epd5eDb2dRNvkD0a3ysFohoAfVFZnJAf9ZZi7oWgDaoOMUvfWV5eB48fMhnu3aENnmMCgUeiVHEV7IycasWp5LC9B6Z%7E-1z5-kDKwIRg__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.226.61.115, 13.226.61.67, 13.226.61.46, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.226.61.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3421905472 (3.2G) [binary/octet-stream]\n",
            "Saving to: ‘Dolphin3.0-Llama3.2-3B-Q8_0.gguf’\n",
            "\n",
            "Dolphin3.0-Llama3.2 100%[===================>]   3.19G  16.0MB/s    in 2m 35s  \n",
            "\n",
            "2025-03-30 00:35:45 (21.0 MB/s) - ‘Dolphin3.0-Llama3.2-3B-Q8_0.gguf’ saved [3421905472/3421905472]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Define files path (corrected relative path)\n",
        "path = \"Understanding_Climate_Change.pdf\" # Assuming the PDF is in the same directory\n",
        "\n",
        "# Helper function to load and encode PDF\n",
        "def encode_pdf(pdf_path: str, chunk_size: int = 500, chunk_overlap: int = 50, embeddings_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"Loads a PDF, splits it into chunks, and encodes it into a FAISS vector store.\"\"\"\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        documents = loader.load()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at path: {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Use Hugging Face Embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
        "\n",
        "    # Create a FAISS vector store\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "#Initialize LlamaCpp language model\n",
        "model_path = \"/content/Dolphin3.0-Llama3.2-3B-Q8_0.gguf\"  # Replace with the actual path to your downloaded model\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=0, # Adjust based on your GPU, set to 0 if no GPU\n",
        "    n_batch=512,\n",
        "    n_ctx=2048, # adjust based on your model\n",
        "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=False, # Verbose is required to pass to the callback manager\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize search tool\n",
        "search = DuckDuckGoSearchResults()\n",
        "\n",
        "# Define retrieval evaluator, knowledge refinement, and query rewriter llm chains\n",
        "# Retrieval Evaluator\n",
        "class RetrievalEvaluatorInput(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n",
        "\n",
        "def retrieval_evaluator(query: str, document: str) -> float:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"document\"],\n",
        "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query, \"document\": document}\n",
        "    try:\n",
        "        result = chain.invoke(input_variables)\n",
        "        # Parse the output to extract the relevance score (assuming the model outputs a number)\n",
        "        try:\n",
        "            score = float(result.strip()) # Try to directly convert to float\n",
        "            return score\n",
        "        except ValueError:\n",
        "            # If direct conversion fails, try to extract the number from the text\n",
        "            import re\n",
        "            match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result) # Search for any float or integer\n",
        "            if match:\n",
        "                score = float(match.group(0))\n",
        "                return score\n",
        "            else:\n",
        "                return 0.5  # Return a neutral score if no number is found\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retrieval evaluator: {e}\")\n",
        "        return 0.5  # Return a neutral score in case of an exception\n",
        "\n",
        "\n",
        "\n",
        "# Knowledge Refinement\n",
        "class KnowledgeRefinementInput(BaseModel):\n",
        "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
        "\n",
        "def knowledge_refinement(document: str) -> List[str]:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"document\"],\n",
        "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"document\": document}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
        "\n",
        "# Web Search Query Rewriter\n",
        "class QueryRewriterInput(BaseModel):\n",
        "    query: str = Field(..., description=\"The query to rewrite.\")\n",
        "\n",
        "def rewrite_query(query: str) -> str:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return result.strip()\n",
        "\n",
        "# Helper function to parse search results\n",
        "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Parse a JSON string of search results into a list of title-link tuples.\n",
        "\n",
        "    Args:\n",
        "        results_string (str): A JSON-formatted string containing search results.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
        "                               If parsing fails, an empty list is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to parse the JSON string\n",
        "        results = json.loads(results_string)\n",
        "        # Extract and return the title and link from each result\n",
        "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
        "    except (json.JSONDecodeError, TypeError):  # Handle TypeError as well\n",
        "        # Handle JSON decoding errors by returning an empty list\n",
        "        print(\"Error parsing search results. Returning empty list.\")\n",
        "        return []\n",
        "\n",
        "# Define sub functions for the CRAG process\n",
        "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Retrieve documents based on a query using a FAISS index.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
        "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of the retrieved document contents.\n",
        "    \"\"\"\n",
        "    docs = faiss_index.similarity_search(query, k=k)\n",
        "    return [doc.page_content for doc in docs]\n",
        "\n",
        "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Evaluate the relevance of documents based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        documents (List[str]): A list of document contents to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: A list of relevance scores for each document.\n",
        "    \"\"\"\n",
        "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
        "\n",
        "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
        "    \"\"\"\n",
        "    Perform a web search based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[Tuple[str, str]]]:\n",
        "            - A list of refined knowledge obtained from the web search.\n",
        "            - A list of tuples containing titles and links of the sources.\n",
        "    \"\"\"\n",
        "    rewritten_query = rewrite_query(query)\n",
        "    web_results = search.run(rewritten_query)\n",
        "    web_knowledge = knowledge_refinement(web_results)\n",
        "    sources = parse_search_results(web_results)\n",
        "    return web_knowledge, sources\n",
        "\n",
        "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response to a query using knowledge and sources.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        knowledge (str): The refined knowledge to use in the response.\n",
        "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    response_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
        "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
        "    )\n",
        "    input_variables = {\n",
        "        \"query\": query,\n",
        "        \"knowledge\": knowledge,\n",
        "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
        "    }\n",
        "    response_chain = response_prompt | llm\n",
        "    return response_chain.invoke(input_variables)\n",
        "\n",
        "# CRAG process\n",
        "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
        "    \"\"\"\n",
        "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to process.\n",
        "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response based on the query.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing query: {query}\")\n",
        "\n",
        "    # Retrieve and evaluate documents\n",
        "    if faiss_index is None:\n",
        "        return \"Error: FAISS index is not initialized. Please check if the PDF was loaded successfully.\"\n",
        "\n",
        "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
        "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
        "\n",
        "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
        "    print(f\"Evaluation scores: {eval_scores}\")\n",
        "\n",
        "    # Determine action based on evaluation scores\n",
        "    if eval_scores: # Ensure eval_scores is not empty\n",
        "        max_score = max(eval_scores)\n",
        "    else:\n",
        "        max_score = 0 # Default to 0 if no documents were retrieved.\n",
        "\n",
        "    sources = []\n",
        "\n",
        "    if max_score > 0.7:\n",
        "        print(\"\\nAction: Correct - Using retrieved document\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        final_knowledge = best_doc\n",
        "        sources.append((\"Retrieved document\", \"\"))\n",
        "    elif max_score < 0.3:\n",
        "        print(\"\\nAction: Incorrect - Performing web search\")\n",
        "        final_knowledge, sources = perform_web_search(query)\n",
        "    else:\n",
        "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        # Refine the retrieved knowledge\n",
        "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
        "        web_knowledge, web_sources = perform_web_search(query)\n",
        "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
        "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
        "\n",
        "    print(\"\\nFinal knowledge:\")\n",
        "    print(final_knowledge)\n",
        "\n",
        "    print(\"\\nSources:\")\n",
        "    for title, link in sources:\n",
        "        print(f\"{title}: {link}\" if link else title)\n",
        "\n",
        "    # Generate response\n",
        "    print(\"\\nGenerating response...\")\n",
        "    response = generate_response(query, final_knowledge, sources)\n",
        "\n",
        "    print(\"\\nResponse generated\")\n",
        "    return response\n",
        "\n",
        "# Initialize vector store\n",
        "vectorstore = encode_pdf(path)\n",
        "\n",
        "\n",
        "# Example queries\n",
        "query1 = \"What are the main causes of climate change?\"\n",
        "query2 = \"how did harry beat quirrell?\"\n",
        "\n",
        "# Process queries and print results\n",
        "if vectorstore:\n",
        "    result1 = crag_process(query1, vectorstore)\n",
        "    print(f\"Query: {query1}\")\n",
        "    print(f\"Answer: {result1}\")\n",
        "\n",
        "    result2 = crag_process(query2, vectorstore)\n",
        "    print(f\"Query: {query2}\")\n",
        "    print(f\"Answer: {result2}\")\n",
        "else:\n",
        "    print(\"Vectorstore was not initialized.  Please check the PDF loading process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US8NPNN6eQJV",
        "outputId": "e0a4c2a1-61d7-4679-dead-c8cce7619d39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "<ipython-input-1-52143e652641>:40: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing query: What are the main causes of climate change?\n",
            " 1 0.5 1\n",
            "Retrieved 3 documents\n",
            "Evaluation scores: [1.0, 0.5, 1.0]\n",
            "\n",
            "Action: Correct - Using retrieved document\n",
            "\n",
            "Final knowledge:\n",
            "provide a historical record that scientists use to understand past climate conditions and \n",
            "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
            "driven by human activities, particularly the emission of greenhouse gases. \n",
            "Chapter 2: Causes of Climate Change \n",
            "Greenhouse Gases \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous\n",
            "\n",
            "Sources:\n",
            "Retrieved document\n",
            "\n",
            "Generating response...\n",
            " The main causes of climate change are primarily driven by human activities, particularly the emission of greenhouse gases. Greenhouse gases in the atmosphere include carbon dioxide (CO2), methane (CH4), and nitrous oxide sources. Retrieved document.\n",
            "\n",
            "Response generated\n",
            "Query: What are the main causes of climate change?\n",
            "Answer:  The main causes of climate change are primarily driven by human activities, particularly the emission of greenhouse gases. Greenhouse gases in the atmosphere include carbon dioxide (CO2), methane (CH4), and nitrous oxide sources. Retrieved document.\n",
            "\n",
            "\n",
            "Processing query: how did harry beat quirrell?\n",
            " 1 0.3\n",
            "\n",
            "The relevance score for the document is 0.3, indicating that the document has a moderate level of relevance to the query \"how did harry beat quirrell?\". 0.1\n",
            "Retrieved 3 documents\n",
            "Evaluation scores: [1.0, 0.3, 0.1]\n",
            "\n",
            "Action: Correct - Using retrieved document\n",
            "\n",
            "Final knowledge:\n",
            "emissions, particularly methane, which is a potent greenhouse gas. Innovations in fracking \n",
            "technology have made natural gas more accessible, but this comes with environmental and \n",
            "health concerns. \n",
            "Deforestation \n",
            "Forests act as carbon sinks, absorbing CO2 from the atmosphere. When trees are cut down \n",
            "for timber or to clear land for agriculture, this stored carbon is released back into the \n",
            "atmosphere. Deforestation reduces the number of trees that can absorb CO2, exacerbating the\n",
            "\n",
            "Sources:\n",
            "Retrieved document\n",
            "\n",
            "Generating response...\n",
            " Harry beat Quirrell by using the power of his emotions and his determination to win. In the second book, Harry further develops this emotional connection with Quirrell as he seeks revenge for all the pain he has endured.\n",
            "\n",
            "Sources: Retrieved document\n",
            "Response generated\n",
            "Query: how did harry beat quirrell?\n",
            "Answer:  Harry beat Quirrell by using the power of his emotions and his determination to win. In the second book, Harry further develops this emotional connection with Quirrell as he seeks revenge for all the pain he has endured.\n",
            "\n",
            "Sources: Retrieved document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Define files path (corrected relative path)\n",
        "path = \"1.pdf\" # Assuming the PDF is in the same directory\n",
        "\n",
        "# Helper function to load and encode PDF\n",
        "def encode_pdf(pdf_path: str, chunk_size: int = 500, chunk_overlap: int = 50, embeddings_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"Loads a PDF, splits it into chunks, and encodes it into a FAISS vector store.\"\"\"\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        documents = loader.load()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at path: {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Use Hugging Face Embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
        "\n",
        "    # Create a FAISS vector store\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "#Initialize LlamaCpp language model\n",
        "model_path = \"/content/Dolphin3.0-Llama3.2-3B-Q8_0.gguf\"  # Replace with the actual path to your downloaded model\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=0, # Adjust based on your GPU, set to 0 if no GPU\n",
        "    n_batch=512,\n",
        "    n_ctx=2048, # adjust based on your model\n",
        "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=False, # Verbose is required to pass to the callback manager\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize search tool\n",
        "search = DuckDuckGoSearchResults()\n",
        "\n",
        "# Define retrieval evaluator, knowledge refinement, and query rewriter llm chains\n",
        "# Retrieval Evaluator\n",
        "class RetrievalEvaluatorInput(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n",
        "\n",
        "def retrieval_evaluator(query: str, document: str) -> float:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"document\"],\n",
        "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query, \"document\": document}\n",
        "    try:\n",
        "        result = chain.invoke(input_variables)\n",
        "        # Parse the output to extract the relevance score (assuming the model outputs a number)\n",
        "        try:\n",
        "            score = float(result.strip()) # Try to directly convert to float\n",
        "            return score\n",
        "        except ValueError:\n",
        "            # If direct conversion fails, try to extract the number from the text\n",
        "            import re\n",
        "            match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", result) # Search for any float or integer\n",
        "            if match:\n",
        "                score = float(match.group(0))\n",
        "                return score\n",
        "            else:\n",
        "                return 0.5  # Return a neutral score if no number is found\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retrieval evaluator: {e}\")\n",
        "        return 0.5  # Return a neutral score in case of an exception\n",
        "\n",
        "\n",
        "\n",
        "# Knowledge Refinement\n",
        "class KnowledgeRefinementInput(BaseModel):\n",
        "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
        "\n",
        "def knowledge_refinement(document: str) -> List[str]:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"document\"],\n",
        "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"document\": document}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
        "\n",
        "# Web Search Query Rewriter\n",
        "class QueryRewriterInput(BaseModel):\n",
        "    query: str = Field(..., description=\"The query to rewrite.\")\n",
        "\n",
        "def rewrite_query(query: str) -> str:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    input_variables = {\"query\": query}\n",
        "    result = chain.invoke(input_variables) # No with_structured_output needed for raw text\n",
        "    return result.strip()\n",
        "\n",
        "# Helper function to parse search results\n",
        "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Parse a JSON string of search results into a list of title-link tuples.\n",
        "\n",
        "    Args:\n",
        "        results_string (str): A JSON-formatted string containing search results.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
        "                               If parsing fails, an empty list is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to parse the JSON string\n",
        "        results = json.loads(results_string)\n",
        "        # Extract and return the title and link from each result\n",
        "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
        "    except (json.JSONDecodeError, TypeError):  # Handle TypeError as well\n",
        "        # Handle JSON decoding errors by returning an empty list\n",
        "        print(\"Error parsing search results. Returning empty list.\")\n",
        "        return []\n",
        "\n",
        "# Define sub functions for the CRAG process\n",
        "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Retrieve documents based on a query using a FAISS index.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
        "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of the retrieved document contents.\n",
        "    \"\"\"\n",
        "    docs = faiss_index.similarity_search(query, k=k)\n",
        "    return [doc.page_content for doc in docs]\n",
        "\n",
        "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Evaluate the relevance of documents based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        documents (List[str]): A list of document contents to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: A list of relevance scores for each document.\n",
        "    \"\"\"\n",
        "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
        "\n",
        "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
        "    \"\"\"\n",
        "    Perform a web search based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[Tuple[str, str]]]:\n",
        "            - A list of refined knowledge obtained from the web search.\n",
        "            - A list of tuples containing titles and links of the sources.\n",
        "    \"\"\"\n",
        "    rewritten_query = rewrite_query(query)\n",
        "    web_results = search.run(rewritten_query)\n",
        "    web_knowledge = knowledge_refinement(web_results)\n",
        "    sources = parse_search_results(web_results)\n",
        "    return web_knowledge, sources\n",
        "\n",
        "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response to a query using knowledge and sources.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        knowledge (str): The refined knowledge to use in the response.\n",
        "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    response_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
        "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
        "    )\n",
        "    input_variables = {\n",
        "        \"query\": query,\n",
        "        \"knowledge\": knowledge,\n",
        "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
        "    }\n",
        "    response_chain = response_prompt | llm\n",
        "    return response_chain.invoke(input_variables)\n",
        "\n",
        "# CRAG process\n",
        "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
        "    \"\"\"\n",
        "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to process.\n",
        "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response based on the query.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing query: {query}\")\n",
        "\n",
        "    # Retrieve and evaluate documents\n",
        "    if faiss_index is None:\n",
        "        return \"Error: FAISS index is not initialized. Please check if the PDF was loaded successfully.\"\n",
        "\n",
        "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
        "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
        "\n",
        "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
        "    print(f\"Evaluation scores: {eval_scores}\")\n",
        "\n",
        "    # Determine action based on evaluation scores\n",
        "    if eval_scores: # Ensure eval_scores is not empty\n",
        "        max_score = max(eval_scores)\n",
        "    else:\n",
        "        max_score = 0 # Default to 0 if no documents were retrieved.\n",
        "\n",
        "    sources = []\n",
        "\n",
        "    if max_score > 0.7:\n",
        "        print(\"\\nAction: Correct - Using retrieved document\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        final_knowledge = best_doc\n",
        "        sources.append((\"Retrieved document\", \"\"))\n",
        "    elif max_score < 0.3:\n",
        "        print(\"\\nAction: Incorrect - Performing web search\")\n",
        "        final_knowledge, sources = perform_web_search(query)\n",
        "    else:\n",
        "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        # Refine the retrieved knowledge\n",
        "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
        "        web_knowledge, web_sources = perform_web_search(query)\n",
        "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
        "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
        "\n",
        "    print(\"\\nFinal knowledge:\")\n",
        "    print(final_knowledge)\n",
        "\n",
        "    print(\"\\nSources:\")\n",
        "    for title, link in sources:\n",
        "        print(f\"{title}: {link}\" if link else title)\n",
        "\n",
        "    # Generate response\n",
        "    print(\"\\nGenerating response...\")\n",
        "    response = generate_response(query, final_knowledge, sources)\n",
        "\n",
        "    print(\"\\nResponse generated\")\n",
        "    return response\n",
        "\n",
        "# Initialize vector store\n",
        "vectorstore = encode_pdf(path)\n",
        "\n",
        "\n",
        "# Example queries\n",
        "query1 = \"What is the name of the author of the book?\"\n",
        "query2 = \"What is the topic of the book?\"\n",
        "\n",
        "# Process queries and print results\n",
        "if vectorstore:\n",
        "    result1 = crag_process(query1, vectorstore)\n",
        "    print(f\"Query: {query1}\")\n",
        "    print(f\"Answer: {result1}\")\n",
        "\n",
        "    result2 = crag_process(query2, vectorstore)\n",
        "    print(f\"Query: {query2}\")\n",
        "    print(f\"Answer: {result2}\")\n",
        "else:\n",
        "    print(\"Vectorstore was not initialized.  Please check the PDF loading process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF_3-mstf7Rg",
        "outputId": "ebd1e9c0-3257-44df-93cc-5ca50ac80953"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "<ipython-input-1-1980208c6801>:40: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing query: What is the name of the author of the book?\n",
            " 1 1 0 (not at all relevant) or 1 (completely irrelevant).\n",
            "Retrieved 3 documents\n",
            "Evaluation scores: [1.0, 1.0, 0.0]\n",
            "\n",
            "Action: Correct - Using retrieved document\n",
            "\n",
            "Final knowledge:\n",
            "To my father, Rick Riordan, Sr., who read\n",
            "me my first book of mythology\n",
            "—R.R.\n",
            "To my heroes of illustration: N. C. Wyeth,\n",
            "Maxfield Parrish, Arthur Rackham, and\n",
            "Frank Frazetta\n",
            "—J.R.\n",
            "\n",
            "Sources:\n",
            "Retrieved document\n",
            "\n",
            "Generating response...\n",
            " The name of the author of the book is Rick Riordan. The sources from where I got this information are: Retrieved document\n",
            "Response generated\n",
            "Query: What is the name of the author of the book?\n",
            "Answer:  The name of the author of the book is Rick Riordan. The sources from where I got this information are: Retrieved document\n",
            "\n",
            "Processing query: What is the topic of the book?\n",
            " 0/1\n",
            "\n",
            "Explanation: The document provided information about a book published by Disney Hyperion. The relevant information is the title of the book and its publisher. However, the relevance score for this document is 0/1 since there is no query or question related to this specific information. 0.5\n",
            "\n",
            "A document's relevance score is a measure of how closely the document answers or touches upon the query.\n",
            "\n",
            "For example, in the case above, where the query asks about the topic of a book and the document contains information about a book title page, it's clear that the document doesn't directly answer the query. Therefore, the relevance score for this particular document is 0.5.\n",
            "\n",
            "It's important to remember that relevance scores are only estimates, as they rely on comparing the content of one or more documents to the specific terms used within the query itself. 1 (scale from 0 to 1)\n",
            "Retrieved 3 documents\n",
            "Evaluation scores: [0.0, 0.5, 1.0]\n",
            "\n",
            "Action: Correct - Using retrieved document\n",
            "\n",
            "Final knowledge:\n",
            "BOOKS BY RICK RIORDAN\n",
            "Percy Jackson and the Olympians Book One:\n",
            "The Lightning Thief\n",
            "Percy Jackson and the Olympians Book Two:\n",
            "The Sea of Monsters\n",
            "Percy Jackson and the Olympians Book\n",
            "Three:\n",
            "The Titan’s Curse\n",
            "Percy Jackson and the Olympians Book\n",
            "Four:\n",
            "The Battle of the Labyrinth\n",
            "Percy Jackson and the Olympians Book Five:\n",
            "The Last Olympian\n",
            "The Demigod Files\n",
            "Percy Jackson’s Greek Gods, illustrated by\n",
            "John Rocco\n",
            "\n",
            "Sources:\n",
            "Retrieved document\n",
            "\n",
            "Generating response...\n",
            " The topic of the book is Percy Jackson and the Olympians. The author Rick Riordan wrote the book. It has four main books: \"The Lightning Thief,\" \"The Sea of Monsters,\" \"The Titan’s Curse,\" and \"The Battle of the Labyrinth.\" There are also two short stories, illustrated children's book, and other related works.\n",
            "Response generated\n",
            "Query: What is the topic of the book?\n",
            "Answer:  The topic of the book is Percy Jackson and the Olympians. The author Rick Riordan wrote the book. It has four main books: \"The Lightning Thief,\" \"The Sea of Monsters,\" \"The Titan’s Curse,\" and \"The Battle of the Labyrinth.\" There are also two short stories, illustrated children's book, and other related works.\n"
          ]
        }
      ]
    }
  ]
}